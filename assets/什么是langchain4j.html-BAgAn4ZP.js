import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,f as n,o as t}from"./app-fUMceUzy.js";const e={};function l(h,i){return t(),a("div",null,i[0]||(i[0]=[n(`<h1 id="示例文章" tabindex="-1"><a class="header-anchor" href="#示例文章"><span>示例文章</span></a></h1><blockquote><p>Google 搜索<strong>自动补全功能</strong>的强大，相信不少朋友都能感受到，它帮助我们更快地“补全”我们所要输入的搜索关键字。那么，它怎么知道我们要输入什么内容？它又是如何工作的？在这篇文章里，我们一起来看看。</p></blockquote><h1 id="什么是langchain" tabindex="-1"><a class="header-anchor" href="#什么是langchain"><span>什么是Langchain</span></a></h1><p><code>Langchain</code> 是一个用于构建基于语言模型的应用程序的框架。它帮助开发者将大语言模型（LLMs）集成到应用程序中，并且提供了一整套工具和组件，使得大模型能够更好的被集成到应用程序中。从而更方便快速的完成基于大模型的应用。LangChain提供两种程序语言的版本：Python版与Javascript版。 LangChain提供了一个标准接口，用于将不同的语言模型（LLM）连接在一起，以及与其他工具和数据源的集成。LangChain还为常见应用程序提供端到端链，如聊天机器人、文档分析和代码生成。 LangChain是由Harrison Chase于2022年10月推出的开源软件项目。它已成为LLM开发中最受欢迎的框架之一。LangChain支持Python和JavaScript语言，并与各种业界有名的LLM一起使用。</p><h1 id="为什么要使用langchain" tabindex="-1"><a class="header-anchor" href="#为什么要使用langchain"><span>为什么要使用Langchain?</span></a></h1><p>作为一名基于应用开发者而言，为什么要基于Langchain？一般来说，基于语言大模型的应用通常要经过如下的步骤:</p><h3 id="_1-api调用" tabindex="-1"><a class="header-anchor" href="#_1-api调用"><span>1. <strong>API调用</strong></span></a></h3><ul><li><strong>接口集成</strong>：Langchain提供了一个统一的接口来接入不同的模型，开发者只需要熟悉 Langchain 的 API，就可以轻松地集成多种模型。</li><li><strong>Token管理</strong>：帮助开发者记录每次 API 调用的 Token 使用情况，方便成本管理和优化资源利用。</li></ul><h3 id="_2-提示词-prompts" tabindex="-1"><a class="header-anchor" href="#_2-提示词-prompts"><span>2. <strong>提示词（Prompts）</strong></span></a></h3><ul><li><strong>提示模板</strong>：创建灵活的提示模板，支持动态插入变量，使得生成的文本更符合具体需求。</li><li><strong>提示优化</strong>：提供工具和方法来优化提示词，提升生成结果的质量和相关性。</li></ul><h3 id="_3-记忆-memory" tabindex="-1"><a class="header-anchor" href="#_3-记忆-memory"><span>3. <strong>记忆（Memory）</strong></span></a></h3><ul><li><strong>短期记忆</strong>：在单次对话或操作中保存上下文信息，确保模型在同一对话中保持连贯性。</li><li><strong>长期记忆</strong>：在多次会话中保留重要信息，使得模型能回忆之前的交互，从而提供更加个性化的体验。</li></ul><h3 id="_4-对话管理-conversation-management" tabindex="-1"><a class="header-anchor" href="#_4-对话管理-conversation-management"><span>4. <strong>对话管理（Conversation Management）</strong></span></a></h3><ul><li><strong>多轮对话</strong>：支持多轮对话中的上下文跟踪，使得模型能够理解和响应连续的问题和请求。</li><li><strong>对话控制</strong>：允许开发者设置对话中的关键节点，例如重定向、总结或打断当前流程。</li></ul><h3 id="_5-工具集成-tool-integration" tabindex="-1"><a class="header-anchor" href="#_5-工具集成-tool-integration"><span>5. <strong>工具集成（Tool Integration）</strong></span></a></h3><ul><li><strong>数据库查询</strong>：通过自然语言生成 SQL 查询，直接从数据库中获取所需的数据。</li><li><strong>API 调用</strong>：集成第三方 API，允许模型从外部数据源中获取信息或执行操作。</li><li><strong>文档检索</strong>：支持从大规模文档库中检索相关内容，结合语言模型生成更加精准的响应。</li></ul><h3 id="_6-输出控制-output-parsers" tabindex="-1"><a class="header-anchor" href="#_6-输出控制-output-parsers"><span>6. <strong>输出控制（Output Parsers）</strong></span></a></h3><ul><li><strong>结构化输出</strong>：将模型生成的文本解析为结构化数据，如 JSON 格式，以便进一步处理。</li><li><strong>自定义解析器</strong>：开发者可以定义自定义的输出解析器，处理特定格式或类型的输出。</li></ul><h3 id="_7-代理-agents" tabindex="-1"><a class="header-anchor" href="#_7-代理-agents"><span>7. <strong>代理（Agents）</strong></span></a></h3><ul><li><strong>行动代理</strong>：根据用户的输入或特定条件，自动选择并执行预设的操作（例如查询数据库、调用 API 等）。</li><li><strong>代理工具</strong>：集成多种工具和 API，构建复杂的任务处理代理。</li></ul><h3 id="_8-流-streams" tabindex="-1"><a class="header-anchor" href="#_8-流-streams"><span>8. <strong>流（Streams）</strong></span></a></h3><ul><li><strong>流处理</strong>：支持流式处理大型文本数据或多步骤任务，使得处理长文本或需要连续输出的任务更高效。</li><li><strong>实时更新</strong>：在长时间任务或持续对话中提供实时更新和结果输出。</li></ul><h3 id="_9-模板化-templates" tabindex="-1"><a class="header-anchor" href="#_9-模板化-templates"><span>9. <strong>模板化（Templates）</strong></span></a></h3><ul><li><strong>任务模板</strong>：为常见任务提供预设模板，简化开发流程，如问答系统、文档生成等。</li><li><strong>自定义模板</strong>：开发者可以创建和共享自己的模板，适应特定业务需求。</li></ul><h3 id="_10-部署与集成" tabindex="-1"><a class="header-anchor" href="#_10-部署与集成"><span>10. <strong>部署与集成</strong></span></a></h3><ul><li><strong>多模型支持</strong>：支持与多个语言模型提供商（如 OpenAI, Hugging Face）的无缝集成。</li><li><strong>本地部署</strong>：支持模型在本地环境中的部署和调用，满足对数据隐私和安全的需求。</li></ul><h3 id="_11-分析与监控-analytics-monitoring" tabindex="-1"><a class="header-anchor" href="#_11-分析与监控-analytics-monitoring"><span>11. <strong>分析与监控（Analytics &amp; Monitoring）</strong></span></a></h3><ul><li><strong>使用分析</strong>：跟踪和分析模型的使用情况，包括调用频率、响应时间、成功率等。</li><li><strong>错误处理与日志</strong>：记录和处理模型生成的错误和异常情况，帮助开发者调试和优化应用。</li></ul><h3 id="_12-链-chains" tabindex="-1"><a class="header-anchor" href="#_12-链-chains"><span>12. 链（Chains）</span></a></h3><ul><li><strong>简单链：</strong> 将多个语言模型调用按顺序连接在一起，形成一个处理流程。每个步骤的输出可以作为下一个步骤的输入。</li><li><strong>复杂链：</strong> 支持分支、并行处理等复杂逻辑，让开发者创建更具逻辑性的工作流程。</li></ul><blockquote><p>Chains并不是必须的，因为我们完全可以自定义一些逻辑，并非要专门使用Chains。</p></blockquote><h3 id="_13-rag" tabindex="-1"><a class="header-anchor" href="#_13-rag"><span>13.RAG</span></a></h3><p>RAG（检索增强生成）是一种结合信息检索与生成式模型的技术，旨在提高文本生成的准确性和相关性。它的典型工作流程是先从外部知识库或文档集合中检索到与问题相关的内容，然后将这些信息与大语言模型结合，用于生成更精确的回答。RAG 的优势在于，它利用了大模型的生成能力，同时通过检索增强了对具体事实和最新信息的掌握，比起finetune，是一种低成本获取精确信息的方案。 在智能问答系统、客服、法律和医学领域有较高的使用场景。</p><p>要使用RAG，必须经过文本向量化、向量存储、文档检索、相关性排序、 生成回答等诸多复杂的流程，Langchain集成了这些基础功能，使用Langchain可以很快的攒出来一个RAG流程。</p><p><strong>因此，Langchain是一个非常重要的AI应用开发框架，其重要性相当于Java生态体系中的Spring。</strong></p><h2 id="什么是langchain4j" tabindex="-1"><a class="header-anchor" href="#什么是langchain4j"><span>什么是Langchain4j</span></a></h2><p>尽管 Python 在数据科学和机器学习领域非常流行，Java 仍然是许多企业级应用的首选语言。为了填补 Java 生态中缺乏类似 LangChain 的框架这一空白，LangChain4j 应运而生。 angChain4J与LangChain的作者不同，也不属于同一个开源家族，但较晚出现的LangChain4J，极大的吸收LangChain的设计精神，并汲取Haystack与LlamaIndex部分设计，尽可能让LangChain4J能赶上LangChain。从2023年初，项目启动到如今，LangChain4j一直在持续更新，集成了诸多AI框架。因此，在java生态要基于大模型做应用，langchain4j是绝对绕不过去的一个选择。 官网地址：https://docs.langchain4j.dev/ 进行了解。</p><h3 id="lanchain4j的基本功能" tabindex="-1"><a class="header-anchor" href="#lanchain4j的基本功能"><span>Lanchain4J的基本功能</span></a></h3><h4 id="轻松与-llm-和-vector-stores-交互" tabindex="-1"><a class="header-anchor" href="#轻松与-llm-和-vector-stores-交互"><span>轻松与 LLM 和 Vector Stores 交互</span></a></h4><p>Langchain4J支持所有主要的商业和开源 LLM 和 Vector Store， 都可以通过统一的 API 轻松访问，从而能能够构建聊天机器人、助手等。</p><h4 id="基础ai服务、rag、工具箱" tabindex="-1"><a class="header-anchor" href="#基础ai服务、rag、工具箱"><span>基础AI服务、RAG、工具箱</span></a></h4><p>从低级提示模板、聊天内存管理、输出解析到 RAG、代码执行引擎、常见LLM使用的工具箱（或者函数调用），Langchain4j都做了实现。</p><h4 id="集成quarkus-和-spring-boot" tabindex="-1"><a class="header-anchor" href="#集成quarkus-和-spring-boot"><span>集成Quarkus 和 Spring Boot</span></a></h4><p>Langchain4j集成了 Quarkus 和 Spring Boot，并且LLM和Java之间是双向集成：可以从 Java 调用 LLM，并允许 LLM 反过来调用Java 代码。</p><h3 id="lanchain4j源码编译" tabindex="-1"><a class="header-anchor" href="#lanchain4j源码编译"><span>Lanchain4J源码编译</span></a></h3><p>langchain4j从上手难度讲，并不复杂，因此可以首先下载齐源码，本地编译，https://github.com/langchain4j/langchain4j</p><p>langchain4j的源码很清晰，从项目结构就可以大致看到Langchain4j集成了哪些AI模型。</p><p>出现很过类IDE无法识别的情况。</p><h4 id="_1-本地编译" tabindex="-1"><a class="header-anchor" href="#_1-本地编译"><span>1.本地编译</span></a></h4><p>先要<code>mvn clean install</code>编译<code>langchain-core</code>，不能跳过测试 因为在其他的项目中，依赖了如下配置：</p><div class="language-xml line-numbers-mode" data-highlighter="shiki" data-ext="xml" data-title="xml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">dependency</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            &lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">groupId</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;dev.langchain4j&lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">groupId</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            &lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">artifactId</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;langchain4j-core&lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">artifactId</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            &lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">classifier</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;tests&lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">classifier</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            &lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">type</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;test-jar&lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">type</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            &lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">scope</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;test&lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">scope</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        &lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">dependency</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这种配置要本地打包,否则无法编译通过。</p><p>2.当Langchaincore编译完成以后，使用mvn clean install maven test.skip=true编译所有项目。</p><p>3.刷新ide：通过 invalide caches 来让idea识别，如果还不行，直接删除.iml文件，重新进入即可。</p><p>快速开始</p><p>当然，效果最好的大模型显然是OpenAPI的ChatGPT，但是其OpenAPI对限制了对中国的开放，但是微软的Azure Open AI服务却没有限制， 因此，我们完全可以使用Azure Open AI代替其OPENAPI的官方服务。当然，我们也可以使用智普、阿里通义千问、商汤商量等国产大模型。</p><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">public</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> class</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> ChatLanguageDemo</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">   public</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> static</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> void</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> main</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[] </span><span style="--shiki-light:#383A42;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span></span>
<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">       ChatLanguageModel</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> model</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> AzureOpenAiChatModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">builder</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">               .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">endpoint</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;#Your Endpoint&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">               .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">apiKey</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;#API KEY&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">               .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">deploymentName</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;#Azure Deployment Name&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">               .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">temperature</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">               .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">logRequestsAndResponses</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">true</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">               .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">serviceVersion</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;2024-02-01&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">               .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">build</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">       System</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">out</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">println</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">model</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">generate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;介绍一下自己&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">));</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   }</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,57)]))}const k=s(e,[["render",l],["__file","什么是langchain4j.html.vue"]]),g=JSON.parse('{"path":"/ai/langchain/%E4%BB%80%E4%B9%88%E6%98%AFlangchain4j.html","title":"示例文章","lang":"zh-CN","frontmatter":{"description":"示例文章 Google 搜索自动补全功能的强大，相信不少朋友都能感受到，它帮助我们更快地“补全”我们所要输入的搜索关键字。那么，它怎么知道我们要输入什么内容？它又是如何工作的？在这篇文章里，我们一起来看看。 什么是Langchain Langchain 是一个用于构建基于语言模型的应用程序的框架。它帮助开发者将大语言模型（LLMs）集成到应用程序中，并...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/Knowledge-Base/ai/langchain/%E4%BB%80%E4%B9%88%E6%98%AFlangchain4j.html"}],["meta",{"property":"og:site_name","content":"MyDataAI"}],["meta",{"property":"og:title","content":"示例文章"}],["meta",{"property":"og:description","content":"示例文章 Google 搜索自动补全功能的强大，相信不少朋友都能感受到，它帮助我们更快地“补全”我们所要输入的搜索关键字。那么，它怎么知道我们要输入什么内容？它又是如何工作的？在这篇文章里，我们一起来看看。 什么是Langchain Langchain 是一个用于构建基于语言模型的应用程序的框架。它帮助开发者将大语言模型（LLMs）集成到应用程序中，并..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-10-13T13:10:19.000Z"}],["meta",{"property":"article:author","content":"MyDataAI"}],["meta",{"property":"article:modified_time","content":"2024-10-13T13:10:19.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"示例文章\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-10-13T13:10:19.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"MyDataAI\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":3,"title":"1. API调用","slug":"_1-api调用","link":"#_1-api调用","children":[]},{"level":3,"title":"2. 提示词（Prompts）","slug":"_2-提示词-prompts","link":"#_2-提示词-prompts","children":[]},{"level":3,"title":"3. 记忆（Memory）","slug":"_3-记忆-memory","link":"#_3-记忆-memory","children":[]},{"level":3,"title":"4. 对话管理（Conversation Management）","slug":"_4-对话管理-conversation-management","link":"#_4-对话管理-conversation-management","children":[]},{"level":3,"title":"5. 工具集成（Tool Integration）","slug":"_5-工具集成-tool-integration","link":"#_5-工具集成-tool-integration","children":[]},{"level":3,"title":"6. 输出控制（Output Parsers）","slug":"_6-输出控制-output-parsers","link":"#_6-输出控制-output-parsers","children":[]},{"level":3,"title":"7. 代理（Agents）","slug":"_7-代理-agents","link":"#_7-代理-agents","children":[]},{"level":3,"title":"8. 流（Streams）","slug":"_8-流-streams","link":"#_8-流-streams","children":[]},{"level":3,"title":"9. 模板化（Templates）","slug":"_9-模板化-templates","link":"#_9-模板化-templates","children":[]},{"level":3,"title":"10. 部署与集成","slug":"_10-部署与集成","link":"#_10-部署与集成","children":[]},{"level":3,"title":"11. 分析与监控（Analytics & Monitoring）","slug":"_11-分析与监控-analytics-monitoring","link":"#_11-分析与监控-analytics-monitoring","children":[]},{"level":3,"title":"12. 链（Chains）","slug":"_12-链-chains","link":"#_12-链-chains","children":[]},{"level":3,"title":"13.RAG","slug":"_13-rag","link":"#_13-rag","children":[]},{"level":2,"title":"什么是Langchain4j","slug":"什么是langchain4j","link":"#什么是langchain4j","children":[{"level":3,"title":"Lanchain4J的基本功能","slug":"lanchain4j的基本功能","link":"#lanchain4j的基本功能","children":[]},{"level":3,"title":"Lanchain4J源码编译","slug":"lanchain4j源码编译","link":"#lanchain4j源码编译","children":[]}]}],"git":{"createdTime":1728825019000,"updatedTime":1728825019000,"contributors":[{"name":"xienng","email":"xienng@qq.com","commits":1}]},"readingTime":{"minutes":7.59,"words":2277},"filePathRelative":"ai/langchain/什么是langchain4j.md","localizedDate":"2024年10月13日","autoDesc":true}');export{k as comp,g as data};
